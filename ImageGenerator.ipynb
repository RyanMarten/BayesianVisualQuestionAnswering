{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyprob #https://github.com/probprog/pyprob #!pip install pyprob\n",
    "from pyprob import Model \n",
    "from pyprob.distributions import Categorical, Uniform, Normal\n",
    "import numpy as np\n",
    "import torch\n",
    "import cv2\n",
    "from pyprob import PriorInflation, InferenceEngine, InferenceNetwork\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImagesGen(Model):\n",
    "    def __init__(self, name='ImagesModel', opt = None):\n",
    "        super().__init__(name=name)\n",
    "        self.opt = opt\n",
    "\n",
    "        self.height, self.width = 75, 75\n",
    "        self.colors = [\n",
    "            (0,0,255),##r\n",
    "            (0,255,0),##g\n",
    "            (255,0,0),##b\n",
    "            (0,156,255),##o\n",
    "            (128,128,128),##k\n",
    "            (0,255,255)##y\n",
    "            ]\n",
    "        self.size = 5\n",
    "\n",
    "    def forward(self):\n",
    "        # Initialize images with 255 (white background)\n",
    "        img = np.ones((self.height,self.width, 3), dtype=np.uint8)*255\n",
    "        objects = []\n",
    "        for color_id,color in enumerate(self.colors):  \n",
    "            center = self.center_generate(objects)\n",
    "            shape = pyprob.sample(Categorical(probs=[0.5,0.5]), name=f\"{color_id}_shape\").item()\n",
    "            if shape:\n",
    "                start = (center[0]-self.size, center[1]-self.size)\n",
    "                end = (center[0]+self.size, center[1]+self.size)\n",
    "                cv2.rectangle(img, start, end, color, -1)\n",
    "                objects.append((color_id,center,'r'))\n",
    "            else:\n",
    "                center_ = (center[0], center[1])\n",
    "                cv2.circle(img, center_, self.size, color, -1)\n",
    "                objects.append((color_id,center,'c'))\n",
    "\n",
    "        rendered_img = torch.tensor(img).view(-1) # I had to add this for some reason --> check if it is right\n",
    "        pyprob.tag(rendered_img, name=\"rendered_image\")\n",
    "        \n",
    "        #Use VAE encoded represenation\n",
    "        # encoded_mu, encoded_sigma = encoder(rendered_img)\n",
    "        # pyprob.observe(Normal(encoded_mu, encoded_sigma), name=\"observed_image\")\n",
    "        pyprob.observe(Normal(rendered_img, 1), name=\"observed_image\")\n",
    "\n",
    "    def center_generate(self, objects):\n",
    "        while True:\n",
    "            pas = True\n",
    "            center_x = pyprob.sample(Categorical(probs=[0] * self.size + [1/(self.height-2*self.size)]*(self.height-2*self.size)), name=f\"{len(objects)}_center_x\").item()\n",
    "            center_y = pyprob.sample(Categorical(probs=[0] * self.size + [1/(self.height-2*self.size)]*(self.height-2*self.size)), name=f\"{len(objects)}_center_y\").item()\n",
    "            #self.np.random.randint(0+size, img_size - size, 2)        \n",
    "            center = torch.tensor([center_x, center_y])\n",
    "            if len(objects) > 0:\n",
    "                for name,c,shape in objects:\n",
    "                    if torch.sum(((center - c) ** 2)) < ((self.size * 2) ** 2):\n",
    "                        pas = False\n",
    "            if pas:\n",
    "                return center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_trace(trace_image, title):\n",
    "    img = np.array(trace_image.view(75,75, 3))\n",
    "    img = img.astype(\"uint8\")\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    plt.title(title)\n",
    "    plt.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = ImagesGen()\n",
    "    \n",
    "gt_trace = next(model._trace_generator(inference_engine=InferenceEngine.RANDOM_WALK_METROPOLIS_HASTINGS))\n",
    "plot_trace(gt_trace[\"rendered_image\"], \"Ground Truth Rendered Image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([255, 255, 255,  ..., 255, 255, 255], dtype=torch.uint8)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_trace[\"rendered_image\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new inference network...\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Tensor.__contains__ only supports Tensor or scalar, but you passed in a <class 'str'>.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-4b3680c96629>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model.learn_inference_network(num_traces=500,\n\u001b[0m\u001b[1;32m      2\u001b[0m                               \u001b[0mobserve_embeddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'observed_image'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mobserved_image\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                               inference_network=pyprob.InferenceNetwork.LSTM)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pyprob/model.py\u001b[0m in \u001b[0;36mlearn_inference_network\u001b[0;34m(self, num_traces, num_traces_end, inference_network, prior_inflation, dataset_dir, dataset_valid_dir, observe_embeddings, batch_size, valid_size, valid_every, optimizer_type, learning_rate_init, learning_rate_end, learning_rate_scheduler_type, momentum, weight_decay, save_file_name_prefix, save_every_sec, pre_generate_layers, distributed_backend, distributed_params_sync_every_iter, distributed_num_buckets, dataloader_offline_num_workers, stop_with_bad_loss, log_file_name, lstm_dim, lstm_depth, proposal_mixture_components)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_network\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_network\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_traces\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_traces\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_valid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_traces_end\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_traces_end\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_every\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate_init\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate_end\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate_end\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate_scheduler_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate_scheduler_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweight_decay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_file_name_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_file_name_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_every_sec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_every_sec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistributed_backend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdistributed_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistributed_params_sync_every_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdistributed_params_sync_every_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistributed_num_buckets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdistributed_num_buckets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_offline_num_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataloader_offline_num_workers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_with_bad_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop_with_bad_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_file_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlog_file_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave_inference_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pyprob/nn/inference_network.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, num_traces, dataset, dataset_valid, num_traces_end, batch_size, valid_every, optimizer_type, learning_rate_init, learning_rate_end, learning_rate_scheduler_type, momentum, weight_decay, save_file_name_prefix, save_every_sec, distributed_backend, distributed_params_sync_every_iter, distributed_num_buckets, dataloader_offline_num_workers, stop_with_bad_loss, log_file_name)\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_traces\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_valid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_traces_end\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mOptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mADAM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate_end\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate_scheduler_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLearningRateScheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNONE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_file_name_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_every_sec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m600\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistributed_backend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistributed_params_sync_every_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistributed_num_buckets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_offline_num_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_with_bad_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_file_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layers_initialized\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_layers_observe_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_observe_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample_trace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layers_initialized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pyprob/nn/inference_network.py\u001b[0m in \u001b[0;36m_init_layers_observe_embedding\u001b[0;34m(self, observe_embeddings, example_trace)\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;31m#     raise ValueError('Observable {}: cannot use this observation as an input to the inference network, because there is no associated likelihood.'.format(name))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0;31m# else:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0;34m'reshape'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m                 \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'reshape'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Observable {}: reshape to {}.'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36m__contains__\u001b[0;34m(self, element)\u001b[0m\n\u001b[1;32m    646\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[union-attr]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 648\u001b[0;31m         raise RuntimeError(\n\u001b[0m\u001b[1;32m    649\u001b[0m             \u001b[0;34m\"Tensor.__contains__ only supports Tensor or scalar, but you passed in a %s.\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m             \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Tensor.__contains__ only supports Tensor or scalar, but you passed in a <class 'str'>."
     ]
    }
   ],
   "source": [
    "model.learn_inference_network(num_traces=500,\n",
    "                              observe_embeddings={'observed_image' : observed_image},\n",
    "                              inference_network=pyprob.InferenceNetwork.LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Cannot run inference engine IMPORTANCE_SAMPLING_WITH_INFERENCE_NETWORK because no inference network for this model is available. Use learn_inference_network or load_inference_network first.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-49f31763170b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# sample from posterior (500 samples)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m posterior_results = model.posterior_results(\n\u001b[0m\u001b[1;32m      3\u001b[0m          \u001b[0mnum_traces\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# the number of samples estimating the posterior\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m          \u001b[0minference_engine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpyprob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInferenceEngine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIMPORTANCE_SAMPLING_WITH_INFERENCE_NETWORK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# specify which inference engine to use\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m          \u001b[0mobserve\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'observed_image'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mgt_trace\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;31m# assign values to the observed values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pyprob/model.py\u001b[0m in \u001b[0;36mposterior_results\u001b[0;34m(self, num_traces, inference_engine, initial_trace, map_func, observe, file_name, thinning_steps, *args, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mposterior_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_traces\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minference_engine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mInferenceEngine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIMPORTANCE_SAMPLING\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_trace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobserve\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthinning_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposterior\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_traces\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_traces\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minference_engine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minference_engine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_trace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_trace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobserve\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobserve\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthinning_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mthinning_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset_inference_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pyprob/model.py\u001b[0m in \u001b[0;36mposterior\u001b[0;34m(self, num_traces, inference_engine, initial_trace, map_func, observe, file_name, thinning_steps, likelihood_importance, *args, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0minference_engine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mInferenceEngine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIMPORTANCE_SAMPLING_WITH_INFERENCE_NETWORK\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_network\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cannot run inference engine IMPORTANCE_SAMPLING_WITH_INFERENCE_NETWORK because no inference network for this model is available. Use learn_inference_network or load_inference_network first.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0mposterior\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_traces\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_traces\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_traces\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTraceMode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPOSTERIOR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minference_engine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minference_engine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minference_network\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_network\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobserve\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobserve\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlikelihood_importance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlikelihood_importance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Cannot run inference engine IMPORTANCE_SAMPLING_WITH_INFERENCE_NETWORK because no inference network for this model is available. Use learn_inference_network or load_inference_network first."
     ]
    }
   ],
   "source": [
    "# sample from posterior (500 samples)\n",
    "posterior_results = model.posterior_results(\n",
    "         num_traces=500, # the number of samples estimating the posterior\n",
    "         inference_engine=pyprob.InferenceEngine.IMPORTANCE_SAMPLING_WITH_INFERENCE_NETWORK, # specify which inference engine to use\n",
    "         observe={'observed_image' : gt_trace} # assign values to the observed values\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
