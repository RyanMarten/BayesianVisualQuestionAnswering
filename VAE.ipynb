{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "987e4069-7938-4a46-8b66-61ca0589f923",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from pyro.contrib.examples.util import MNIST\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import pyro.contrib.examples.util  # patches torchvision\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "from pyro.optim import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1989997b-a680-4221-8f4f-6117203a69c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a015bff3-49df-4f1e-b29f-e3efe45d28df",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/sort-of-clevr.pickle\", \"rb\") as fp:\n",
    "    train_data, test_data = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f76f9f25-5d28-4c1a-bc51-d51f76cb77d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16875"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0][0].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c26b69e7-7096-4f46-9ce6-4fda0aa90c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_data_loaders(batch_size=128, use_cuda=False):\n",
    "    root = './data'\n",
    "    download = True\n",
    "    trans = transforms.ToTensor()\n",
    "    train_set = MNIST(root=root, train=True, transform=trans,\n",
    "                      download=download)\n",
    "    test_set = MNIST(root=root, train=False, transform=trans)\n",
    "\n",
    "    kwargs = {'num_workers': 1, 'pin_memory': use_cuda}\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_set,\n",
    "        batch_size=batch_size, shuffle=True, **kwargs)\n",
    "    test_loader = torch.utils.data.DataLoader(dataset=test_set,\n",
    "        batch_size=batch_size, shuffle=False, **kwargs)\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5e530368-bac8-41bb-b571-5a60a065c949",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, z_dim):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc21 = nn.Linear(hidden_dim, z_dim)\n",
    "        self.fc22 = nn.Linear(hidden_dim, z_dim)\n",
    "        \n",
    "        self.softplus = nn.Softplus()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.reshape(-1, input_dim)\n",
    "        hidden = self.softplus(self.fc1(x))\n",
    "        mu = self.softplus(self.fc21(hidden))\n",
    "        logsigma = self.softplus(self.fc22(hidden))\n",
    "        \n",
    "        return mu, logsigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba9cc69f-824c-4b17-9866-4b11db4346f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, z_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(z_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "        self.softplus = nn.Softplus()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, z):\n",
    "        hidden = self.softplus(self.fc1(z))\n",
    "        out = self.sigmoid(self.fc2(hidden))\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ae8e55f2-8aef-4b45-9109-3da96b19a0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    \n",
    "    def __init__(self, z_dim=64, hidden_dim=400, data_dim=16875, use_cuda=False):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(data_dim, hidden_dim, z_dim)\n",
    "        self.decoder = Decoder(z_dim, hidden_dim, data_dim)\n",
    "        \n",
    "        if use_cuda:\n",
    "            self.cuda()\n",
    "            \n",
    "        self.use_cuda = use_cuda\n",
    "        self.z_dim = z_dim\n",
    "    \n",
    "    def model(self, x):\n",
    "        pyro.module(\"decoder\", self.decoder)\n",
    "        with pyro.plate(\"data\", x.shape[0]):\n",
    "            z_loc = x.new_zeros(torch.Size((x.shape[0], self.z_dim)))\n",
    "            z_scale = x.new_ones(torch.Size((x.shape[0], self.z_dim)))\n",
    "            \n",
    "            z = pyro.sample(\"latent\", dist.Normal(z_loc, z_scale).to_event(1))\n",
    "            loc_img = self.decoder(z)\n",
    "            pyro.sample(\"obs\", dist.Bernoulli(loc_img).to_event(1), obs=x.reshape(-1, 784))\n",
    "            \n",
    "    def guide(self, x):\n",
    "        pyro.module(\"encoder\", self.encoder)\n",
    "        with pyro.plate(\"data\", x.shape[0]):\n",
    "            z_loc, z_scale = self.encoder(x)\n",
    "            pyro.sample(\"latent\", dist.Normal(z_loc, z_scale).to_event(1))\n",
    "        \n",
    "    def reconstruct_img(self, x):\n",
    "        z_loc, z_scale = self.encoder(x)\n",
    "        z = dist.Normal(z_loc, z_scale).sample()\n",
    "        loc_img = self.decoder(z)\n",
    "        return loc_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b372de2-55fd-4ef0-9e5a-efd84e9440b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = VAE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0a668b7-bc5d-42c3-ab8e-b97f22612760",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam({\"lr\": 1.0e-3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c45d94f-e9c5-4565-a704-c99612358343",
   "metadata": {},
   "outputs": [],
   "source": [
    "svi = SVI(vae.model, vae.guide, optimizer, loss=Trace_ELBO())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4330b33-8776-4e9a-a16a-d6b8335df432",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(svi, train_loader, use_cuda=False):\n",
    "    epoch_loss = 0.\n",
    "    for x, _ in train_loader:\n",
    "        if use_cuda:\n",
    "            x = x.cuda()\n",
    "        epoch_loss += svi.step(x)\n",
    "        \n",
    "    normalizer_train = len(train_loader.dataset)\n",
    "    total_epoch_loss_train = epoch_loss / normalizer_train\n",
    "    return total_epoch_loss_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3f6905a-2680-4311-8f9a-fd72e83ff69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(svi, test_loader, use_cuda=False):\n",
    "    test_loss = 0.\n",
    "    for x, _ in test_loader:\n",
    "        if use_cuda:\n",
    "            x = x.cuda()\n",
    "        test_loss += svi.evaluate_loss(x)\n",
    "    normalizer_test = len(test_loader.dataset)\n",
    "    total_epoch_loss_test = test_loss / normalizer_test\n",
    "    return total_epoch_loss_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1d89eb5c-fa2b-4007-9c5c-6e6881db0796",
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 1.0e-3\n",
    "USE_CUDA = False\n",
    "\n",
    "NUM_EPOCHS = 10\n",
    "TEST_FREQUENCY = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce825ed-cf83-4a96-bf4e-1d71995dc109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 000]  average training loss: 211.0555\n",
      "[epoch 000] average test loss: 198.2412\n",
      "[epoch 001]  average training loss: 187.0577\n",
      "[epoch 002]  average training loss: 163.9005\n",
      "[epoch 003]  average training loss: 151.2199\n",
      "[epoch 004]  average training loss: 143.8359\n"
     ]
    }
   ],
   "source": [
    "train_loader, test_loader = setup_data_loaders(batch_size=256, use_cuda=USE_CUDA)\n",
    "\n",
    "# clear param store\n",
    "pyro.clear_param_store()\n",
    "\n",
    "# setup the VAE\n",
    "vae = VAE(use_cuda=USE_CUDA)\n",
    "\n",
    "# setup the optimizer\n",
    "adam_args = {\"lr\": LEARNING_RATE}\n",
    "optimizer = Adam(adam_args)\n",
    "\n",
    "# setup the inference algorithm\n",
    "svi = SVI(vae.model, vae.guide, optimizer, loss=Trace_ELBO())\n",
    "\n",
    "train_elbo = []\n",
    "test_elbo = []\n",
    "# training loop\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    total_epoch_loss_train = train(svi, train_loader, use_cuda=USE_CUDA)\n",
    "    train_elbo.append(-total_epoch_loss_train)\n",
    "    print(\"[epoch %03d]  average training loss: %.4f\" % (epoch, total_epoch_loss_train))\n",
    "\n",
    "    if epoch % TEST_FREQUENCY == 0:\n",
    "        # report test diagnostics\n",
    "        total_epoch_loss_test = evaluate(svi, test_loader, use_cuda=USE_CUDA)\n",
    "        test_elbo.append(-total_epoch_loss_test)\n",
    "        print(\"[epoch %03d] average test loss: %.4f\" % (epoch, total_epoch_loss_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a55417f-bd10-4701-bcac-060239ddb1cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
